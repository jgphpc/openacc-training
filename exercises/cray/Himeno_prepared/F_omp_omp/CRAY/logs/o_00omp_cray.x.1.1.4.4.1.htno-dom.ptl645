# -----------------------------------------------
# core file size          (blocks, -c) unlimited
# data seg size           (kbytes, -d) unlimited
# scheduling priority             (-e) 0
# file size               (blocks, -f) unlimited
# pending signals                 (-i) 511579
# max locked memory       (kbytes, -l) 64
# max memory size         (kbytes, -m) 65986560
# open files                      (-n) 16384
# pipe size            (512 bytes, -p) 8
# POSIX message queues     (bytes, -q) 819200
# real-time priority              (-r) 0
# stack size              (kbytes, -s) unlimited
# cpu time               (seconds, -t) unlimited
# max user processes              (-u) 511579
# virtual memory          (kbytes, -v) unlimited
# file locks                      (-x) unlimited
# -----------------------------------------------
# -----------------------------------------------
# SLURM_JOB_NODELIST = nid00005
# SLURM_JOB_NUM_NODES = 1
# SLURM_JOB_ID = 656544
# SLURM_JOBID = 656544
# SLURM_NTASKS = 1 / -n --ntasks
# SLURM_NTASKS_PER_NODE = 1 / -N --ntasks-per-node
# SLURM_CPUS_PER_TASK = 4 / -d-c --cpus-per-task
# OMP_NUM_THREADS = 4 / -d-c 
# SLURM_NTASKS_PER_CORE = 1 / -j1 --ntasks-per-core
# -----------------------------------------------
# -----------------------------------------------
# SLURM_CPUS_ON_NODE = 12
# SLURM_LOCALID = 0
# SLURM_NNODES = 1
# SLURM_NODEID = 0
# SLURM_PROCID = 0
# SLURM_NPROCS = 1
# SLURM_OVERCOMMIT = 
# nodeid:0 taskid:0 localid:0
# 
# -----------------------------------------------
Mon May  1 20:31:28 CEST 2017
+ echo CRAY_CUDA_MPS=
CRAY_CUDA_MPS=
+ echo HUGETLB_DEFAULT_PAGE_SIZE=
HUGETLB_DEFAULT_PAGE_SIZE=
+ echo HUGETLB_MORECORE=
HUGETLB_MORECORE=
+ /usr/bin/time -p srun --unbuffered --ntasks=1 --ntasks-per-node=1 --cpus-per-task=4 --ntasks-per-core=1 --hint=nomultithread --bcast=/tmp/cray.x ./cray.x
[CCE OMP: host=nid00005 pid=24190 tid=24190 id=0] thread 0 affinity:  0-3
CrayPat/X:  Version 6.4.5 Revision 87dd5b8  01/23/17 15:37:24
[CCE OMP: host=nid00005 pid=24190 tid=24214 id=0] thread 1 affinity:  0-3
[CCE OMP: host=nid00005 pid=24190 tid=24215 id=0] thread 2 affinity:  0-3
[CCE OMP: host=nid00005 pid=24190 tid=24216 id=0] thread 3 affinity:  0-3
 
 Double precision
 
 PROBLEM_SIZE :  3
   mimax =  257  mjmax =  129  mkmax =  129
   imax =  256  jmax =  128  kmax =  128
 
 Using OpenMP
   OMP_NUM_THREADS :  4
 
 Iterations  :  3
 Time (secs) :  3.8991119246929884E-2
 Gosa       : 0.169217378263115037E-02 
 MFLOPS      :  10548.951041778224
 
 Iterations  :  100
 Time (secs) :  1.202719712513499
 Gosa       : 0.137835972438405665E-02 
 MFLOPS      :  11399.591656602301
 Score based on Pentium III 600MHz : 137.60974959684089

#################################################################
#                                                               #
#            CrayPat-lite Performance Statistics                #
#                                                               #
#################################################################

CrayPat/X:  Version 6.4.5 Revision 87dd5b8  01/23/17 15:37:24
Experiment:                  lite  lite/sample_profile
Number of PEs (MPI ranks):      1
Numbers of PEs per Node:        1
Numbers of Threads per PE:      4
Number of Cores per Socket:    12
Execution start time:  Mon May  1 20:31:29 2017
System name and speed:  nid00005  2601 MHz (approx)
Intel haswell CPU  Family:  6  Model: 63  Stepping:  2


Avg Process Time:          1.36 secs          
High Memory:              529.4 MBytes  529.4 MBytes per PE
MFLOPS:           Not supported (see observation below)
I/O Read Rate:         5.389593 MBytes/sec        
I/O Write Rate:       14.557006 MBytes/sec        
Avg CPU Energy:             161 joules    161 joules per node
Avg CPU Power:           118.47 watts  118.47 watts per node

Table 1:  Profile by Function

  Samp% |  Samp | Imb. |  Imb. |Group
        |       | Samp | Samp% | Function=[MAX10]
        |       |      |       |  Thread=HIDE
       
 100.0% | 132.0 |   -- |    -- |Total
|--------------------------------------------------------------
|  96.2% | 127.0 |   -- |    -- |USER
||-------------------------------------------------------------
||  91.7% | 121.0 |  2.5 |  2.8% |jacobi_clone_73259_2_.LOOP@li.0
||   2.3% |   3.0 |  0.0 |  0.0% |jacobi_clone_73259_1_.LOOP@li.0
||   1.5% |   2.0 |  1.2 | 55.6% |initmt_.LOOP@li.212
||=============================================================
|   3.0% |   4.0 |   -- |    -- |ETC
||-------------------------------------------------------------
||   1.5% |   2.0 |  0.0 |  0.0% |__cray_dset_HSW
|==============================================================

Table 2:  Profile by Group, Function, and Line

  Samp% |  Samp | Imb. |  Imb. |Group
        |       | Samp | Samp% | Function=[MAX10]
        |       |      |       |  Source
        |       |      |       |   Line
        |       |      |       |    Thread=HIDE
       
 100.0% | 132.0 |   -- |    -- |Total
|-----------------------------------------------------------------------------
|  96.2% | 127.0 |   -- |    -- |USER
||----------------------------------------------------------------------------
||  91.7% | 121.0 |  2.5 |  2.8% |jacobi_clone_73259_2_.LOOP@li.0
||   2.3% |   3.0 |  0.0 |  0.0% |jacobi_clone_73259_1_.LOOP@li.0
||   1.5% |   2.0 |   -- |    -- |initmt_.LOOP@li.212
3|        |       |      |       | Himeno_prepared/F_omp_omp/CRAY/himeno_F_v00.F90
||============================================================================
|   3.0% |   4.0 |   -- |    -- |ETC
||----------------------------------------------------------------------------
||   1.5% |   2.0 |  0.0 |  0.0% |__cray_dset_HSW
|=============================================================================

===================  Observations and suggestions  ===================


MFLOPS not available on Intel Haswell:

    The document that specifies performance monitoring events for Intel
    processors does not include events that could be used to compute a
    count of floating point operations for Haswell processors: Intel 64
    and IA-32 Architectures Software Developer's Manual, Order Number
    253665-050US, February 2014.


MPI utilization:

    No suggestions were made because each node has only one rank.

=========================  End Observations  =========================

Table 3:  File Input Stats by Filename

     Read |     Read |  Read Rate | Reads | Bytes/ |File Name[max10]
     Time |   MBytes | MBytes/sec |       |   Call |
         
 0.000030 | 0.000163 |   5.389593 |   8.0 |  21.38 |Total
|-------------------------------------------------------------------
| 0.000030 | 0.000163 |   5.389593 |   8.0 |  21.38 |/proc/cpuinfo
|===================================================================

Table 4:  File Output Stats by Filename

    Write |    Write | Write Rate | Writes | Bytes/ |File Name[max10]
     Time |   MBytes | MBytes/sec |        |   Call |
         
 0.000045 | 0.000656 |  14.557006 |   23.0 |  29.91 |Total
|--------------------------------------------------------------------
| 0.000033 | 0.000212 |   6.449241 |    3.0 |  74.00 |stderr
| 0.000012 | 0.000444 |  36.293363 |   20.0 |  23.30 |stdout
|====================================================================

Program invocation:  /tmp/cray.x

For a complete report with expanded tables and notes, run:
  pat_report /scratch/snx2000tds/piccinal/openacc/cray.x+24190-5s.ap2

For help identifying callers of particular functions:
  pat_report -O callers+src /scratch/snx2000tds/piccinal/openacc/cray.x+24190-5s.ap2
To see the entire call tree:
  pat_report -O calltree+src /scratch/snx2000tds/piccinal/openacc/cray.x+24190-5s.ap2

For interactive, graphical performance analysis, run:
  app2 /scratch/snx2000tds/piccinal/openacc/cray.x+24190-5s.ap2

================  End of CrayPat-lite output  ==========================
real 5.41
user 1.26
sys 0.16
+ set +x
